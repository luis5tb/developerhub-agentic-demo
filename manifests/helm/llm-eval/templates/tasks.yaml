# ---
# apiVersion: tekton.dev/v1beta1
# kind: Task
# metadata:
#   name: create-lmeval-data
#   namespace: {{ .Values.namespace }}
#   labels:
#     backstage.io/kubernetes-id: ${{values.component_id}}
# spec:
#   params:
#     - name: model
#       type: string
#     - name: tokenizer
#       type: string
#   workspaces:
#     - name: lmeval-data
#       description: "PVC to store the Hugging Face model"
#   steps:
#     - name: download-model
#       image: registry.access.redhat.com/ubi9/ubi:latest
#       script: |
#         #!/bin/sh
#         set -e
#         export MODEL_DIR="/workspace/lmeval-data/$(params.model)"
#         rm -rf $MODEL_DIR
#         export MODEL_NAME="$(params.tokenizer)"

#         echo "Downloading tokenizer: $MODEL_NAME with authentication using snapshot_download"

#         # Ensure Hugging Face CLI and dependencies are installed
#         yum install -y python3 python-pip
#         pip install --no-cache-dir --upgrade huggingface_hub

#         python3 - <<EOF
#         import os
#         from huggingface_hub import login, snapshot_download

#         hf_token = os.getenv('HF_TOKEN')
#         model_repo = os.getenv('MODEL_NAME')
#         model_path = os.getenv('MODEL_DIR')

#         login(token=hf_token)
#         snapshot_download(repo_id=model_repo, local_dir=model_path)

#         print(f"Model downloaded to: {model_path}")
#         EOF

#         echo "Download complete. Model stored in $MODEL_DIR"
#       env:
#         - name: HF_TOKEN
#           valueFrom:
#             secretKeyRef:
#               name: huggingface-secret
#               key: hf_token
---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: lmeval-task
  namespace: {{ .Values.namespace }}
  labels:
    backstage.io/kubernetes-id: ${{values.component_id}}
spec:
  params:
    - name: job_name
      description: name of the lm eval job
      type: string
    - name: model
      description: name of the model to evaluate
      type: string
    - name: url
      description: model endpoint
      type: string
    - name: num_concurrent
      description: Concurrent requests
      type: string
    - name: max_retries
      description: Max retries
      type: string
    - name: tokenized_requests
      description: Tokenized requests
      type: string
    - name: tokenizer
      description: Tokenizer
      type: string
    - name: tasks_name
      type: array
      description: Eval Tasks to use (only set task_name or task_recipe_X)
      default: []
    - name: task_recipe_card_name
      type: string
      description: Eval Recipe Card Name to use (Either the card_name or card_custom should be filled)
      default: ""
    - name: task_recipe_card_custom
      type: string
      description: Eval Recipe Card Custom to use (Either the card_name or card_custom should be filled)
      default: ""
    - name: task_recipe_template
      type: string
      description: Eval Recipe Template
      default: ""
  steps:
    - name: run-lmeval
      image: {{ .Values.evalOptions.baseImage }}
      args:
        - "$(params.tasks_name[*])"
      script: |
        cat <<EOF > /workspace/shared-data/evaljob.yaml
        apiVersion: trustyai.opendatahub.io/v1alpha1
        kind: LMEvalJob
        metadata:
          name: $(params.job_name)
          namespace: {{ .Values.namespace }}
        spec:
          model: local-completions
          taskList:
        EOF

        if [ "$#" -gt 0 ] && [ -n "$1" ]; then
            echo "    taskNames:" >> /workspace/shared-data/evaljob.yaml
            for task in "$@"; do
              echo "      - $task" >> /workspace/shared-data/evaljob.yaml
            done
        elif [ -n "$(params.task_recipe_template)" ]; then
          echo "    taskRecipes:" >> /workspace/shared-data/evaljob.yaml
          echo "    - template:" >> /workspace/shared-data/evaljob.yaml
          echo "        name: \"$(params.task_recipe_template)\"" >> /workspace/shared-data/evaljob.yaml
          echo "      card:" >> /workspace/shared-data/evaljob.yaml
          if [ -n "$(params.task_recipe_card_name)" ]; then
            echo "        name: \"$(params.task_recipe_card_name)\"" >> /workspace/shared-data/evaljob.yaml
          elif [ -n "$(params.task_recipe_card_custom)" ]; then
            echo "        custom: |" >> /workspace/shared-data/evaljob.yaml
            echo "\"$(params.task_recipe_card_custom)\"" | sed 's/^/          /' >> /workspace/shared-data/evaljob.yaml
          fi
        else
          echo "Error: Either tasks_names or task_recipe_* must be provided."
          exit 1
        fi

        cat <<EOF >> /workspace/shared-data/evaljob.yaml
          logSamples: true
          batchSize: "1"
          allowOnline: true
          allowCodeExecution: true
          modelArgs:
            - name: model
              value: $(params.model)
            - name: base_url
              value: $(params.url)/v1/completions
            - name: num_concurrent
              value: "$(params.num_concurrent)"
            - name: max_retries
              value: "$(params.max_retries)"
            - name: tokenized_requests
              value: "$(params.tokenized_requests)"
            - name: tokenizer
              value: $(params.tokenizer)
            - name: verify_certificate
              value: "{{ $.Values.evalOptions.verifyCertificate }}"
          #offline:
          #  storage:
          #    pvcName: "lmeval-data"
          pod:
            container:
              env:
              - name: OPENAI_API_KEY
                valueFrom:
                      secretKeyRef:
                        name: {{ $.Values.saName }}-{{ $.Values.modelName }}-sa
                        key: token
              - name: HF_TOKEN
                valueFrom:
                  secretKeyRef:
                    name: huggingface-secret
                    key: hf_token
              resources:
                  limits:
                    cpu: '1'
                    memory: 8Gi
                    nvidia.com/gpu: '1'
                  requests:
                    cpu: '1'
                    memory: 8Gi
                    nvidia.com/gpu: '1'
          outputs:
            pvcManaged:
              size: 5Gi
        EOF

        cat /workspace/shared-data/evaljob.yaml
        oc create -f /workspace/shared-data/evaljob.yaml

        # Wait for job completion
        oc wait -n {{ .Values.namespace }} --timeout=3600s --for=condition=complete lmevaljob/$(params.job_name)
  workspaces:
    - name: shared-data
